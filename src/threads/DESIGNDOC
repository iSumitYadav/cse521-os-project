			+--------------------+
			|       CSE 521      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

Sumit Kumar <skumar34@buffalo.edu>
Keshav Jethaliya <keshavje@buffalo.edu>
Christopher Sam Roy <croy2@buffalo.edu>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

	===========
	in thread.h
	===========

	1. int64_t wakeup_ticks;								// NEW MEMBER of struct thread
		Wakeup_ticks needs to be calculated based on the current system ticks and the number of ticks for which the thread is sleeping.

	2. struct list_elem elem_ptr;								// NEW MEMBER of struct thread
		elem_ptr is used to iterate pointer in sleep thread


	===========
	in timer.c
	===========

	1. int64_t ticks;									
		Wakeup_ticks needs to be calculated based on the current system ticks and the number of ticks for which the thread is sleeping.

	2. struct semaphore t_sema;									
		The t_sema semaphore of a thread will help us maintain synchronization between multiple threads.
	
	3. static struct list thread_sleep_insert_ordered;		
		We will define a new list thread_sleep_insert_ordered which is used to sort threads in increasing order of wakeup ticks.

	4. struct thread * current_thread;							// in timer_sleep()
		current_thread is used to store the current thread.

	5. static bool value_less()
		value_less() is a function, which compares the wakeup_ticks of all the threads, in the sleeping thread list, with the current ticks, and returns a boolean value accordingly.


---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

	timer_sleep() will be modified to remove busy waiting by calculating the wakeup_ticks of the calling thread and pushing it to a sleeping thread list which is sorted on wakeup_ticks. It will also block the threads after adding to sleeping thread list. As timer_interrupt() is called on every tick we can check there if any thread in the sleeping list needs to wake up, if the waking time of the thread has come, it'll be waken up and removed from the sleeping thread list, unblocked and added to the ready list.

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

	Sorted sleeping thread list based on ascending wakeup_ticks is used to save the thread which needs to be waken up by their wake up ticks, so for every tick it is checked whether a thread(s) needs to be waken up, instead of checking the full unordered list.



---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

	Semaphore will be used to avoid race condition between multiple thread calls to timer_sleep()


>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

	Semaphore will be used to avoid race condition even if an interrupt occurs during a call to timer_sleep()


---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

	We've removed busy waiting from timer_sleep() which was wasting the cpu by doing nothing, we've used sorted list based on wakeup_ticks of the threads and waking them up in timer_interrupt() which already runs on every ticks of the system, and it is optimized by checking only the threads whose waking up ticks has alrady passed. Before this, we thought of an unordered list maintaining sleeping threads, but that needs to be iterated fully on every tick inside timer_interrupt().


			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

	===========
	in thread.h
	===========

	1. static bool value_less_prio();							
		value_less_prio() is a function, which compares the priority of 2 threads, and returns a boolean value accordingly.

	===========
	in thread.h
	===========

	1. struct thread * front_thread_ptr;								// in thread_create()
		front_thread_ptr stores the first thread from the ready list, to compare the priority with the current thread.

	2. int old_priority;										// in thread_set_priority()
		old_priority stores the priority of the current thread, to compare it with the new priority.

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)


	+-------+						+-------+						+-------+
	|		|		+------+		|		|		+------+		|		|
	|	H	|------>|Lock 1|------->|	M	|------>|Lock 2|------->|	L	|
	|		|		+------+		|		|		+------+		|		|
	+-------+						+-------+						+-------+

	**the arrows towards lock represents thread requesting for that particular lock, and arrow towards thread represents lock acquired by the thread.


	We are thinking of developing priority donations using pointers, where a pointer will be used to point to the lock requesting by the thread, and a pointer which points towards the thread which is currently acquired by the thread.


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

	Whenever a thread waits for acquiring a particular lock, we encounter two possibilities:
		- lock is free or
		- lock is acquired by other thread.

	If lock is held by a currently running thread we add the requesting thread to priority based waiting queue which sorts the threads based on their priority and as soon as the lock is availabe the head from this queue is popped and provided with the lock.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

	When a thread calls lock_acquire(), again two possibilities needs to be addressed:
		- if lock is free then it can be directly acquired by the requesting thread or
		- if the lock is already acquired by a thread and a new thread is requesting lock with higher priority then the priority of current thread is saved in a variable and the priority of requesting thread is copied. This ensures that current thread finishes execution and releases the lock which is then acquired by requesting thread, which then finishes execution, thereby succesfully implementing priority donation.

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

	When the lock_release() is called, we have to make sure that the original priority of the thread has to be restored. Also we have to keep track of all the threads who have donated and acquired priorities. Whenever a thread calls lock_release(), we find the thread whose priority this thread has acquired using the list of priority donated threads. Then the priority of current thread is set to its original priority and we monitor the lock of the thread we found from the list of priority donated threads.

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

	When we do priority donation, the donor sets the priority of the thread, but at the same time, the thread may itself want to change its priority. If they both sets the priority in different order, it might result in race condition. 

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

	In this design, we have made the memory allocation very efficient. Instead of using too many variables for every single thing, we are directly calling the functions and returning wherever needed.
Another approach I thought of using, was to sort the ready list according to priority after putting a thread into the ready list. This was taking extra memory. Instead we chose to insert the thread at
appropriate position in the sorted ready list.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

	===========
	in thread.h
	===========

	1. int nice;					// NEW MEMBER of struct thread
		nice value of a particular thread, can be ranged b/w +20 to -20, a positive value denotes it can give up some of its CPU time, while a -ve value denotes it fetches cpu time from other threads

	2. int recent_cpu;				// NEW MEMBER of struct thread
		denotes the CPU time the thread got recently


	===========
	in thread.c
	===========

	1. void increment_recent_cpu_mlfqs()

	2. void calculate_priority_mlfqs()

	3. void calculate_load_avg_mlfqs()

	4. void update_prio_recent_cpu_mlfq()
	
	5. void calculate_recent_cpu()


	//Added new file
	================
	in fixed_point.h
	================



---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

timer  	recent_cpu    	priority   	thread
ticks   A   B   C   	A   B   C   	to run
-----  	--  --  --  	--  --  --   	------
 0	0   1	2	63  61	59	A	
 4	4   1	2	62  61	59	A	
 8	7   2	4	61  61	58	B	
12	6   6	6	61  59	58	A	
16	9   6	7	60  59	57	A	
20	12  6	8	60  59	57	A	
24	15  6	9	59  59	57	B	
28	14  10	10	59  58	57	A	
32	16  10	11	58  58	56	B	
36	15  14	12	59  57	56	A	

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

	Yes, it will be ambiguous, if there comes two thread which have the same priority, as to which thread to run.

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

	Outside the the interrupt context, we are only resetting the value of nice. Other functionalities, like checking the priority, changing the recent_cpu are being done inside the interrupt context.
Though, priority checking is done every 4 ticks, and the recent_cpu is needed to be checked every 100 ticks. So, it will slightly improve the performance, than doing these thing on every tick.


---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

	Advantage:
	
	We used a single linked list, instead of 64 linked list for 64 priorities, so it takes much less space.

	Disadvantages:

	As we have used a single linked list, we have sort it every time, so it takes much more time. In all there is a space-time paradox. 

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

	As we know that Pintos does not support floating point numbers, so we convert all floating point to integers. In our code, nice and priority are integers but the recent_cpu and load_avg are real numbers, which returns floating point numbers. Therefore we use 17.14 to convert to integers as mentioned in pintos manual.

			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
